# Python 機器學習 (Python Machine Learning) 
```
Python 機器學習 (Python Machine Learning) 
Sebastian Raschka 著，劉立民、吳建華 譯
出版商:博碩 出版日期:2016-09-14

https://github.com/rasbt/python-machine-learning-book

https://github.com/rasbt/python-machine-learning-book-2nd-edition#whats-new-in-the-second-edition-from-the-first-edition
```
```
第1章 賦予電腦學習資料的能力1
1.1構建智慧型機器將資料轉化為知識1
1.2 機器學習的三種不同方法1
1.2.1 通過監督學習對未來事件進行預測2
1.2.2 通過強化學習解決互動式問題4
1.2.3 通過無監督學習發現資料本身潛在的結構4
1.2.4 基本術語及符號介紹5
1.3 構建機器學習系統的藍圖6
1.3.1 數據預處理6
1.3.2 選擇預測模型類型並進行訓練7
1.3.3 模型驗證與使用未知數據進行預測8
1.4 Python在機器學習中的應用8


第2章 機器學習分類演算法10
2.1 人造神經元—早期機器學習概覽10
2.2 使用Python實現感知器學習演算法13
2.3 自我調整線性神經元及其學習的收斂性19
2.3.1 通過梯度下降最小化代價函數20
2.3.2 使用Python實現自我調整線性神經元21
2.3.3 大規模機器學習與隨機梯度下降25


第3章 使用scikit-learn實現機器學習分類演算法30
3.1 分類演算法的選擇30
3.2 初涉scikit-learn的使用30
使用scikit-learn訓練感知器31
3.3 邏輯斯諦回歸中的類別概率34
3.3.1 初識邏輯斯諦回歸與條件概率34
3.3.2 通過邏輯斯諦回歸模型的代價函數獲得權重36
3.3.3 使用scikit-learn訓練邏輯斯諦回歸模型37
3.3.4 通過正則化解決過擬合問題39
3.4 使用支持向量機最大化分類間隔41
3.4.1 對分類間隔最大化的直觀認識41
3.4.2 使用鬆弛變數解決非線性可分問題42
3.4.3 使用scikit-learn實現SVM44
3.5 使用核SVM解決非線性問題44
3.6 決策樹48
3.6.1 最大化資訊增益—獲知盡可能準確的結果49
3.6.2 構建決策樹52
3.6.3 通過隨機森林將弱分類器集成為強分類器53
3.7 惰性學習演算法—k-近鄰演算法54


第4章 數據預處理—構建好的訓練資料集58
4.1 缺失資料的處理58
4.1.1 將存在缺失值的特徵或樣本刪除59
4.1.2 缺失數據填充60
4.1.3 理解scikit-learn預估器的API60
4.2 處理類別資料61
4.2.1 有序特徵的映射61
4.2.2 類標的編碼62
4.2.3 標稱特徵上的獨熱編碼63
4.3 將資料集劃分為訓練資料集和測試資料集64
4.4 將特徵的值縮放到相同的區間65
4.5 選擇有意義的特徵66
4.5.1 使用L1正則化滿足資料稀疏化67
4.5.2 序列特徵選擇演算法70
4.6 通過隨機森林判定特徵的重要性74


第5章 通過降維壓縮資料77
5.1 無監督資料降維技術—主成分分析77
5.1.1 總體方差與貢獻方差78
5.1.2 特徵轉換80
5.1.3 使用scikit-learn進行主成分分析82
5.2 通過線性判別分析壓縮無監督資料84
5.2.1 計算散佈矩陣85
5.2.2 在新特徵子空間上選取線性判別演算法87
5.2.3 將樣本映射到新的特徵空間89
5.2.4 使用scikit-learn進行LDA分析90
5.3 使用核主成分分析進行非線性映射91
5.3.1 核函數與核技巧91
5.3.2 使用Python實現核主成分分析94
5.3.3 映射新的資料點99
5.3.4 scikit-learn中的核主成分分析102


第6章 模型評估與參數調優實戰104
6.1 基於流水線的工作流104
6.1.1 載入威斯康辛乳腺癌資料集104
6.1.2 在流水線中集成資料轉換及評估操作105
6.2 使用k折交叉驗證評估模型性能106
6.2.1 holdout方法106
6.2.2 k折交叉驗證107
6.3 通過學習及驗證曲線來調試演算法110
6.3.1 使用學習曲線判定偏差和方差問題110
6.3.2 通過驗證曲線來判定過擬合與欠擬合112
6.4 使用網格搜索調優機器學習模型113
6.4.1 使用網路搜索調優超參114
6.4.2 通過嵌套交叉驗證選擇演算法115
6.5 瞭解不同的性能評價指標116
6.5.1 讀取混淆矩陣116
6.5.2 優化分類模型的準確率和召回率117
6.5.3 繪製ROC曲線118
6.5.4 多類別分類的評價標準121


第7章 集成學習—組合不同的模型122
7.1 集成學習122
7.2 實現一個簡單的多數投票分類器125
7.3 評估與調優集成分類器131
7.4 bagging —通過bootstrap樣本構建集成分類器135
7.5 通過自我調整boosting提高弱學習機的性能138


第8章 使用機器學習進行情感分析144
8.1 獲取IMDb電影評論資料集144
8.2 詞袋模型簡介146
8.2.1 將單詞轉換為特徵向量146
8.2.2 通過詞頻-逆文檔頻率計算單詞關聯度147
8.2.3 清洗文本資料148
8.2.4 標記文檔149
8.3 訓練用於文檔分類的邏輯斯諦回歸模型151
8.4 使用大資料—線上演算法與外存學習152


第9章 在Web應用中嵌入機器學習模型156
9.1 序列化通過scikit-learn擬合的模型156
9.2 使用SQLite資料庫存儲資料158
9.3 使用Flask開發Web應用160
9.3.1 第一個Flask Web應用160
9.3.2 表單驗證及渲染161
9.4 將電影分類器嵌入Web應用164
9.5 在公共伺服器上部署Web應用169


第10章 使用回歸分析預測連續型目標變數173
10.1 簡單線性回歸模型初探173
10.2 波士頓房屋資料集174
10.3 基於最小二乘法構建線性回歸模型178
10.3.1 通過梯度下降計算回歸參數178
10.3.2 使用scikit-learn估計回歸模型的係數181
10.4 使用RANSAC擬合高魯棒性回歸模型182
10.5 線性回歸模型性能的評估184
10.6 回歸中的正則化方法185
10.7 線性回歸模型的曲線化-多項式回歸186
10.7.1 房屋資料集中的非線性關係建模188
10.7.2 使用隨機森林處理非線性關係190


第11章 聚類分析——處理無類標資料194
11.1 使用k-means演算法對相似物件進行分組194
11.1.1 k-means++196
11.1.2 硬聚類與軟聚類198
11.1.3 使用肘方法確定簇的最佳數量199
11.1.4 通過輪廓圖定量分析聚類品質200
11.2 層次聚類203
11.2.1 基於距離矩陣進行層次聚類204
11.2.2 樹狀圖與熱度圖的關聯207
11.2.3 通過scikit-learn進行凝聚聚類208
11.3 使用DBSCAN劃分高密度區域209


第12章 使用人工神經網路識別圖像213
12.1 使用人工神經網路對複雜函數建模213
12.1.1 單層神經網路回顧214
12.1.2 多層神經網路架構簡介215
12.1.3 通過正向傳播構造神經網路216
12.2 手寫數位的識別218
12.2.1 獲取MNIST資料集218
12.2.2 實現一個多層感知器222
12.3 人工神經網路的訓練228
12.3.1 計算邏輯斯諦代價函數228
12.3.2 通過反向傳播訓練神經網路230
12.4 建立對反向傳播的直觀認識231
12.5 通過梯度檢驗調試神經網路232
12.6 神經網路的收斂性236
12.7 其他神經網路架構237
12.7.1 卷積神經網路237
12.7.2 迴圈神經網路238
12.8 關於神經網路的實現239


第13章 使用Theano並行訓練神經網路241
13.1 使用Theano構建、編譯並運行運算式241
13.1.1 什麼是Theano242
13.1.2 初探Theano243
13.1.3 配置Theano244
13.1.4 使用陣列結構245
13.1.5 整理思路—線性回歸示例247
13.2 為前饋神經網路選擇激勵函數250
13.2.1 邏輯斯諦函數概述250
13.2.2 通過softmax函數評估多類別分類任務中的類別概率252
13.2.3 通過雙曲正切函數增大輸出範圍252
13.3 使用Keras提高訓練神經網路的效率254
```
